conf:
  triliovault:
    ## Valid values are "nfs" and "s3"
    backup_target_type: "nfs"
    nfs:
      nfs_shares: 
      - path: /mnt/tvault/42424
        ip: 192.168.1.33
        node_selector_key: openstack-compute-node
        node_selector_value: enabled
      nfs_options: "nolock,soft,vers=3,timeo=180,intr,lookupcache=none"
      storage_class_name: nfs
    s3:
      access_key: ''
      secret_key: ''
      ## S3 region, if your s3 does not have any region, just keep the parameter as it is
      region_name: ''
      bucket: ''
      endpoint_url: ''
      signature_version: 'default'
      auth_version: 'DEFAULT'
      ## If S3 backend is not Amazon S3 and SSL is enabled on S3 endpoint url then change it to 'True', otherwise keep it as 'False'
      ssl_enabled: False
    ## Configure 'dmapi_workers' parameter of '/etc/dmapi/dmapi.conf' file
    ## This parameter value used to spawn the number of dmapi processes to handle the incoming api requests.
    ## If your dmapi node has ‘n' cpu cores, It is recommended, to set this parameter to '4*n’.
    ## If dmapi_workers field is not present in config file. The Default value will be equals to number of cores present on the node
    datamover_api_workers: 16

    cloud_admin_user_name: "admin"
    cloud_admin_project_name: "admin"
    cloud_admin_domain_name: "default"
    ## Provide any role name as your preference. 
    ## Significance: To run any backups in triliovault an openstack user needs to have this role on given project. 
    trustee_role: "creator"
    ## Keystone endpoint interface that triliovault workloadmgr services will use to communicate to other openstack services
    ## Valid values: internal, public, admin
    interface: "internal"
    ## If triliovault docker images are used from a authentication enabled registry, then make this variable value to 'true'
    ## Otherwise set it to 'false'
    docker_registry_auth_enabled: true
